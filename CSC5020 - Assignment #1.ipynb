{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Class: 1\n",
      " ===============================\n",
      "Recall -P: 0.5623003194888179\n",
      "Precision -P: 0.7213114754098361\n",
      "F-Score -P: 0.6319569120287253\n",
      "\n",
      "Scores for Class: 2\n",
      " ===============================\n",
      "Recall -P: 0.6480263157894737\n",
      "Precision -P: 0.7060931899641577\n",
      "F-Score -P: 0.6758147512864494\n",
      "\n",
      "Scores for Class: 3\n",
      " ===============================\n",
      "Recall -P: 0.6228571428571429\n",
      "Precision -P: 0.6707692307692308\n",
      "F-Score -P: 0.645925925925926\n",
      "\n",
      "Scores for Class: 4\n",
      " ===============================\n",
      "Recall -P: 0.6296296296296297\n",
      "Precision -P: 0.6559485530546624\n",
      "F-Score -P: 0.6425196850393701\n",
      "\n",
      "Scores for Class: 5\n",
      " ===============================\n",
      "Recall -P: 0.6718266253869969\n",
      "Precision -P: 0.7161716171617162\n",
      "F-Score -P: 0.6932907348242812\n",
      "\n",
      "\n",
      "Total Scores:  \n",
      "\n",
      "Average Recall -Macro: 0.6269280066304121\n",
      "Average Recall -Micro: 0.6270136307311028\n",
      "Average F-Score -Macro: 0.6587876604567571\n",
      "Average F-Score -Micro: 0.6579973992197659\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as panda\n",
    "features = [\"utterance\",\"frame\",\"coefficient1\",\"coefficient2\",\"coefficient3\",\"coefficient4\",\"coefficient5\",\"coefficient6\",\"coefficient7\",\"coefficient8\",\"coefficient9\",\"coefficient10\",\"coefficient11\",\"coefficient12\",\"binaryClass\"]\n",
    "dosya = panda.read_csv(\"C:/Users/canimaginerc/Desktop/kdd_JapaneseVowels.csv\", skiprows=1, names=features)\n",
    "dosya = dosya.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#####################################################################################\n",
    "#     CFG       CFG       CFG       CFG       CFG       CFG       CFG       CFG     #\n",
    "#####################################################################################\n",
    "hiddenNeuron = 8                                                                    #\n",
    "learning_rate = 0.03                                                                #\n",
    "epoch = 5000                                                                        #\n",
    "trainingSize = 1500                                                                 #\n",
    "###Do not touch below                                                               #\n",
    "inputRows = 14                                                                      #\n",
    "output = 1                                                                          #\n",
    "overfit = 0                                                                         #\n",
    "#####################################################################################\n",
    "trainO, testO, traini = [], [], []\n",
    "# Tahmin sınıflandırması için; \"N\"-0'lar için 0'dan en uzağı bulmak için \"fMax\" ile, \"P\"-1'ler için 1'den en uzağı bulmak için de \"tMax kullanacağız\n",
    "FP, TP, FN, TN, fMax, tMax = 0, 0, 0, 0, 0, 1\n",
    "#W1, W2, B1, B2 = 0, 0, 0, 0\n",
    "\n",
    "################################################################\n",
    "def validation(x):\n",
    "    valSets = [1, 2, 3, 4, 5] # We call a number which choosen for test, other part of validations gets union.\n",
    "    valSets.remove(x)\n",
    "    \n",
    "    #Test Set Determines Here\n",
    "    testInput = dosya.iloc[((x-1)*1992):(x*1992), 0:14]\n",
    "    testOutput = dosya.iloc[((x-1)*1992):(x*1992), 14:15]\n",
    "    \n",
    "    \n",
    "    #Training Validation Sets Gets Union Here\n",
    "    setIndex = valSets[0]\n",
    "    inputSet = dosya.iloc[((setIndex-1)*1992):(setIndex*1992), 0:14]\n",
    "    outputSet = dosya.iloc[((setIndex-1)*1992):(setIndex*1992), 14:15]\n",
    "    for i in range(1,4):\n",
    "        setIndex = valSets[i]\n",
    "        tmpInputSet = dosya.iloc[((setIndex-1)*1992):(setIndex*1992), 0:14]\n",
    "        inputSet = inputSet.append(tmpInputSet, ignore_index = True)\n",
    "        tmpOutputSet = dosya.iloc[((setIndex-1)*1992):(setIndex*1992), 14:15]\n",
    "        outputSet = outputSet.append(tmpOutputSet, ignore_index = True)\n",
    "    return(inputSet, outputSet, testInput, testOutput)\n",
    "\n",
    "#It's change to OutputDF's (train and test -both of it) to \"0-1\" matrices\n",
    "def dftomatrix(trainSDF, trainDF, testDF):\n",
    "    inputM, trDFm, teDFm, tmpi = [], [], [], []    \n",
    "    \n",
    "    #Input DataFrame to Matrix\n",
    "    for i in range(7968):\n",
    "        tmpi = trainSDF.values[i]\n",
    "        inputM.append(tmpi)\n",
    "\n",
    "    #Train Output DF and Test Output DF to Matrices\n",
    "    for i in range(1992):\n",
    "        if trainDF.values[i] == \"N\":\n",
    "            trDFm.append(0)\n",
    "        else:\n",
    "            trDFm.append(1)\n",
    "\n",
    "    for i in range(1992):\n",
    "        if testDF.values[i] == \"N\":\n",
    "            teDFm.append(0)\n",
    "        else:\n",
    "            teDFm.append(1)\n",
    "    return (inputM, trDFm, teDFm)\n",
    "\n",
    "\n",
    "\n",
    "def randoom():\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.normal(0, 1, (hiddenNeuron, inputRows))\n",
    "    W2 = np.random.normal(0, 1, (output, hiddenNeuron))\n",
    "\n",
    "    B1 = np.random.random((hiddenNeuron, 1))\n",
    "    B2 = np.random.random((output, 1))\n",
    "    return (W1, W2, B1, B2)\n",
    "\n",
    "def sigmoid(z, derv=False):\n",
    "    if derv: return z * (1 - z)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def forward(x, predict=False):\n",
    "    a1 = x.reshape(x.shape[0], 1)\n",
    "\n",
    "    z2 = W1.dot(a1) + B1\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    z3 = W2.dot(a2) + B2\n",
    "    a3 = sigmoid(z3)\n",
    "\n",
    "    if predict: return a3\n",
    "    return (a1, a2, a3)\n",
    "\n",
    "\n",
    "dW1 = 0\n",
    "dW2 = 0\n",
    "\n",
    "dB1 = 0\n",
    "dB2 = 0\n",
    "\n",
    "\n",
    "def train(X, y, tW1, tW2, tB1, tB2):\n",
    "    for i in range(epoch):\n",
    "        \n",
    "        dW1 = 0\n",
    "        dW2 = 0\n",
    "\n",
    "        dB1 = 0\n",
    "        dB2 = 0\n",
    "        \n",
    "        for j in range(trainingSize):\n",
    "\n",
    "            # Forward\n",
    "            a0 = X[j].reshape(X[j].shape[0], 1)\n",
    "\n",
    "            z1 = tW1.dot(a0) + tB1\n",
    "            a1 = sigmoid(z1)\n",
    "\n",
    "            z2 = tW2.dot(a1) + tB2\n",
    "            a2 = sigmoid(z2)\n",
    "\n",
    "            # Back\n",
    "            dz2 = a2 - y[j]\n",
    "            dW2 += dz2 * a1.T\n",
    "\n",
    "            dz1 = np.multiply((tW2.T * dz2), sigmoid(a1, derv=True))\n",
    "            dW1 += dz1.dot(a0.T)\n",
    "\n",
    "            dB1 += dz1\n",
    "            dB2 += dz2\n",
    "\n",
    "        \n",
    "        tW1 = tW1 - learning_rate * (dW1 / trainingSize) + ( (overfit / trainingSize) * tW1)\n",
    "        tW2 = tW2 - learning_rate * (dW2 / trainingSize) + ( (overfit / trainingSize) * tW2)\n",
    "\n",
    "        tB1 = tB1 - learning_rate * (dB1 / trainingSize)\n",
    "        tB2 = tB2 - learning_rate * (dB2 / trainingSize)\n",
    "    return (tW1, tW2, tB1, tB2)\n",
    "#####################################################################################################\n",
    "\n",
    "def testFunc(FP, TP, FN, TN, tesT, tesTyC):\n",
    "    fMax, tMax = 0, 1\n",
    "    for i in range(1992):\n",
    "        deger = forward(tesT.values[i], predict=True)\n",
    "        if tesTyC[i] == 0:\n",
    "            if deger  > 0.31:\n",
    "                FP += 1\n",
    "                if deger > fMax:\n",
    "                    fMax = deger\n",
    "            else:\n",
    "                TN += 1\n",
    "                if deger > fMax:\n",
    "                    fMax = deger\n",
    "        \n",
    "\n",
    "        elif tesTyC[i] == 1:\n",
    "            if deger <= 0.31:\n",
    "                FN += 1\n",
    "                if deger < tMax:\n",
    "                    tMax = deger\n",
    "            else:\n",
    "                TP += 1\n",
    "                if deger < tMax:\n",
    "                    tMax = deger\n",
    "   # These rows used for get information while trying to find optimal values\n",
    "   # print(str(fMax) + \"  --  \" + str(tMax))\n",
    "   # print(\"TP: \" + str(TP) + \"    TN: \" + str(TN) +\"\\n\" + \"FP: \" + str(FP) + \"    FN: \" + str(FN))\n",
    "    \n",
    "    return (FP, TP, FN, TN, fMax, tMax)\n",
    " #Calculation Functions   \n",
    "#####################################################################################################\n",
    "def reCallP (FP, TP, FN, TN):\n",
    "    if TP == 0:\n",
    "        return (0.01)\n",
    "    else:\n",
    "        return (TP/(TP + FN))\n",
    "def preCisionP (FP, TP, FN, TN):\n",
    "    if TP == 0:\n",
    "        return (0.01)\n",
    "    else:\n",
    "        return (TP/(TP + FP))\n",
    "def fScoreP (FP, TP, FN, TN):\n",
    "    if TP == 0:\n",
    "        return (0.01)\n",
    "    else:\n",
    "        return (2*((preCisionP(FP, TP, FN, TN)*reCallP(FP, TP, FN, TN))/(preCisionP(FP, TP, FN, TN)+reCallP(FP, TP, FN, TN))))\n",
    "def averageRecallMacro(avReMa):\n",
    "    aRMS = np.matrix(avReMa)\n",
    "    aRMS = aRMS.sum()\n",
    "    aRM = aRMS / len(avReMa)\n",
    "    return (aRM)\n",
    "    \n",
    "def averageRecallMicro(TPS, FNS):\n",
    "    trpos =  np.matrix(TPS)\n",
    "    trpos = trpos.sum()\n",
    "    faneg = np.matrix(FNS)\n",
    "    faneg = faneg.sum()\n",
    "    avReMi = trpos / (trpos + faneg)\n",
    "    return (avReMi)\n",
    "    \n",
    "def averagePrecisionMacro(avPrMa):\n",
    "    aPMS = np.matrix(avPrMa)\n",
    "    aPMS = aPMS.sum()\n",
    "    aPM = aPMS / len(avPrMa)\n",
    "    return (aPM)\n",
    "def averagePrecisionMicro(TPM, FPM):\n",
    "    trposs =  np.matrix(TPM)\n",
    "    trposs = trposs.sum()\n",
    "    fapos = np.matrix(FPM)\n",
    "    fapos = fapos.sum()\n",
    "    avRrMi = trposs / (trposs + fapos)\n",
    "    return (avRrMi)\n",
    "\n",
    "#####################################################################################################\n",
    "FPs, TPs, FNs, TNs, recalls, precisions = [], [], [], [], [], []\n",
    "for i in range(1,6): #Validation Loop\n",
    "    FP, TP, FN, TN, fMax, tMax = 0, 0, 0, 0, 0, 1\n",
    "\n",
    "    trainSet, trainOut, testInput, testOutput = validation(i)\n",
    "\n",
    "    traini, trainO, testO = dftomatrix(trainSet,  trainOut, testOutput)\n",
    "\n",
    "    W1, W2, B1, B2 = randoom()\n",
    "\n",
    "    W1, W2, B1, B2 = train(traini, trainO, W1, W2, B1, B2)\n",
    "\n",
    "    FP, TP, FN, TN, fMax, tMax = testFunc(FP, TP, FN, TN, testInput, testO)\n",
    "    \n",
    "    FPs.append(FP)\n",
    "    TPs.append(TP)\n",
    "    FNs.append(FN)\n",
    "    TNs.append(TN)\n",
    "    recalls.append(reCallP(FP, TP, FN, TN))\n",
    "    precisions.append(preCisionP(FP, TP, FN, TN))\n",
    "\n",
    "    print(\"Scores for Class: \" + str(i) + \"\\n ===============================\")\n",
    "    print(\"Recall -P: \" + str(reCallP(FP, TP, FN, TN)))\n",
    "    print(\"Precision -P: \" + str(preCisionP(FP, TP, FN, TN)))\n",
    "    print(\"F-Score -P: \" + str(fScoreP(FP, TP, FN, TN)) + \"\\n\")\n",
    "\n",
    "print(\"\\nTotal Scores:  \\n\")\n",
    "print(\"Average Recall -Macro: \" + str(averageRecallMacro(recalls)))    \n",
    "print(\"Average Recall -Micro: \" + str(averageRecallMicro(TPs, FNs)))\n",
    "print(\"Average F-Score -Macro: \" + str((2*((averageRecallMacro(recalls)*averagePrecisionMacro(precisions))/(averageRecallMacro(recalls)+averagePrecisionMacro(precisions))))))\n",
    "print(\"Average F-Score -Micro: \" + str((2*((averagePrecisionMicro(TPs, FPs)*averageRecallMicro(TPs, FNs))/(averagePrecisionMicro(TPs, FPs)+averageRecallMicro(TPs, FNs))))))      \n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
